{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Project 3: Collaboration and Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal and Enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the project, I built agents that will collaborate on tennis playing task. Details could be seen from [ReadMe](https://https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/README.md) \n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1. If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01. Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The environment is considered solved, when the average (over 100 episodes) of maximum of each agent's scores is at least +0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the project I adopted the highly suggested *multi-agent deep deterministic policy gradient* (MADDPG) algorithm. The algorithm used is based on a natural extension of the DDPG algorithms described in these papers:\n",
    "\n",
    "* [MADDPG](https://arxiv.org/pdf/1706.02275.pdf)\n",
    "\n",
    "* [DDPG](https://arxiv.org/pdf/1509.02971.pdf)\n",
    "\n",
    "Details of these algorithms are below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Foundation of MADDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-Critic Method and DDPG\n",
    "\n",
    "In general, one can use a policy based method to optimize the policy gradient directly. Actor-critic methods leverage the strengths of both policy-based and value-based methods. Using a policy-based approach, the agent (actor) learns how to act by directly estimating the optimal policy and maximizing reward through gradient ascent. Meanwhile, employing a value-based approach, the agent (critic) learns how to estimate the value (i.e., the future cumulative reward) of different state-action pairs. Actor-critic methods combine these two approaches in order to accelerate the learning process. Actor-critic agents are also more stable than value-based agents, while requiring fewer training samples than policy-based agents. The detailed algorithm for DDPG is already elaborated during [last project](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p2_continuous-control/Report.ipynb).\n",
    "\n",
    "In this environment the agents interact cooperatively and they have identical capabilities, and so a single DDPG agent could have been trained to play both agents rather than MADDPG. One version of such implementation can be found at the [Github](https://github.com/tommytracey/DeepRL-P3-Collaboration-Competition).\n",
    "\n",
    "However, there are a number of important applications that involve interaction between multiple agents, where emergent behavior and complexity arise from agents co-evolving together. Unfortunately, traditional reinforcement learning approaches such as Q-Learning or policy gradient are poorly suited to multi-agent environments. One issue is that each agent's policy is changing\n",
    "as training progresses, and the environment becomes non-stationary from the perspective of any individual agent (in a way that is not explainable by changes in the agent's own policy). This presents learning stability challenges and prevents the straightforward use of past experience replay, which is crucial for stabilizing deep Q-learning. Policy gradient methods, on the other hand, usually exhibit very high variance when coordination of multiple agents is required. Alternatively, one can use model based policy optimization which can learn optimal policies via back-propagation, but this requires a (differentiable) model of the world dynamics and assumptions about the interactions between agents. Applying these methods to competitive environments is also challenging from an optimization perspective, as evidenced by the notorious instability of adversarial training methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Agent Actor Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-agent setting introduces several additional complexities. For example, from the perspective of a single agent, it is tempting to view other agents as part of the environment,as if they merely receive an action and output a state response. We have argued in the previous section that naïve policy gradient methods perform poorly in simple multi-agent settings. \n",
    "\n",
    "In 2017, OpenAI published a new [breakthrough](https://openai.com/blog/learning-to-cooperate-compete-and-communicate/) on multi-agent RL. The MADDPG [paper](https://arxiv.org/pdf/1706.02275.pdf) introduces the concept of centralized training but de-centralized execution as a work-around for this problem. \n",
    "\n",
    "In their work, they propose a general-purpose multi-agent learning algorithm that: (1) leads to learned policies that only use local information (i.e. their own observations) at execution time, (2) does not assume a differentiable model of the environment dynamics or any particular structure on the communication method between agents, and (3) is applicable not only to cooperative interaction but to competitive or mixed interaction involving both physical and communicative behavior. The ability to act in mixed cooperative-competitive environments may be critical for intelligent agents; while competitive training provides a natural curriculum for learning, agents must also exhibit cooperative behavior (e.g. with humans) at execution time.\n",
    "\n",
    "The paper adopts the framework of centralized training with decentralized execution, allowing the policies to use extra information to ease training, so long as this information is not used at test time. It is a simple extension of actor-critic policy gradient methods where the critic is augmented with extra information about the policies of other agents, while the actor only has access to local information. After training is completed, only the local actors are used at execution phase, acting in a decentralized manner and equally applicable in cooperative and competitive settings.\n",
    "\n",
    "Essentially each critic is augmented to receive as inputs the actions and states of all other agents as well as it's own, and during updates utilized other agent's actors and target actors rather than viewing them as part of the environment. This omniscient critic is used to train the actor, by performing gradient ascent on the critic's evaluation of the actor's action. During execution outside of training though the actor is able to act freely without access to other agent's internal models.\n",
    "\n",
    "\n",
    "More precisely, consider a game with N agents with policies parameterized by $\\theta$, and let $\\pi$ be the set of all agent policies. Then one can write the gradient of the expected return for agent $i$, $J(\\theta_i) = \\mathbb{E}[R_i]$ as:\n",
    "\n",
    "\n",
    "$$ \\nabla_{\\theta_i} J(\\theta_i) = \\mathbb{E}[\\nabla_{\\theta_i} \\log \\pi_i (a_i | o_i) Q_i^\\pi (x, a_1, ..., a_N) ]$$\n",
    "\n",
    "Here $Q_i^\\pi (x, a_1, ..., a_N)$ is a centralized action-value function that takes as input the actions of all agents, in addition to some state information x, and outputs the Q-value for agent i. In the simplest case, x could consist of the observations of all agents, however we could also include additional state information if available. Since each $Q^π_i$ is learned separately, agents can have arbitrary reward structures, including conflicting rewards in a competitive setting.\n",
    "\n",
    "We extend the above idea to work with deterministic policies. If we now consider N continuous policies $\\mu_{\\theta_i}$ w.r.t. parameters $\\theta_i$, the gradient can be written as:\n",
    "\n",
    "$$ \\nabla_{\\theta_i} J(\\mu_i) = \\mathbb{E}[\\nabla_{\\theta_i} \\mu_i (a_i | o_i) \\nabla_{a_i} Q_i^\\mu (x, a_1, ..., a_N)|_{a_i=\\mu_i(o_i)}] $$\n",
    "\n",
    "\n",
    "The centralized action-value function $ Q_i^\\mu$ is updated according to:\n",
    "\n",
    "$$\\mathcal{L} = \\mathbb{E}[(Q_i^\\mu (x, a_1, ..., a_N) - y )^2], $$\n",
    "where $ y = R_i+ \\gamma Q_i^{\\mu'} (x', a_1', ..., a_N')$. $\\mu'$ here is the set of target policies with delayed parameters $\\theta_i'$.\n",
    "      \n",
    "\n",
    "Please find the DDPG logic implemented as part of the `MADDPG()` class in [`maddpg.py`](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/maddpg.py#L30) of the source code. The networks $\\mu$ and $Q$ can be found via their respective `Network(actor=True)` and `Network(actor=False)` classes [networkforall.py](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/networkforall.py).\n",
    "\n",
    "Note that in the paper MADDPG also includes some other additions, such as prioritized experience replay and policy ensembles, which were not used in this implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience Replay\n",
    "Experience replay allows the RL agent to learn from past experience.\n",
    "\n",
    "As with DDPG in the previous project, MADDPG also utilizes a replay buffer to gather experiences from each agent. Each experience is stored in a replay buffer as the agent interacts with the environment. In this project, there is one central replay buffer utilized by both agents, therefore allowing agents to learn from each others' experiences.  \n",
    "\n",
    "The replay buffer contains a collection of experience tuples with the state, action, reward, and next state $(s, a, R, s')$. Each agent samples from this buffer as part of the learning step. Experiences are sampled randomly, so that the data is uncorrelated. This prevents action values from oscillating or diverging catastrophically, since a naive algorithm could otherwise become biased by correlations between sequential experience tuples.\n",
    "\n",
    "Also, experience replay improves learning through repetition. By doing multiple passes over the data, our agents have multiple opportunities to learn from a single experience tuple. This is particularly useful for state-action pairs that occur \n",
    "infrequently within the environment.\n",
    "\n",
    "The implementation of the replay buffer can be found in the [`buffer.py`](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/buffer.py) of the source code.\n",
    "\n",
    "Also, the size of the buffer is also very important to the success of the training. Initially I was using the default buffer size 1e5, however, it reached the target performance very slow with this size. Finally, I changed the size to 4e4 and reached the performances shown in this report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration vs Exploitation\n",
    "One challenge is choosing which action to take while the agent is still learning the optimal policy. Should the agent choose an action based on the rewards observed thus far? Or, should the agent try a new action in hopes of earning a higher reward? This is known as the **exploration vs. exploitation dilemma**.\n",
    "\n",
    "In this project, we encourage the exploration in two stages. In the first 100 episodes, we will execute a pure random policy before the learning process get started. Secondly, we'll use the same **Ornstein-Uhlenbeck process**, as suggested in the previously project to solve this dilemma during the training. The Ornstein-Uhlenbeck process adds a certain amount of noise to the action values at each time step. This noise is correlated to previous noise, and therefore tends to stay in the same direction for longer durations without canceling itself out. This allows the rackets to maintain momentum and explore the action space with more continuity.\n",
    "\n",
    "You can find the Ornstein-Uhlenbeck process implemented  in the class of [`OUNoise.py`](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/OUNoise.py) from the source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code used here is adapted from the [\"Physical Deception Lab\"](https://classroom.udacity.com/nanodegrees/nd893/) tutorial from the Deep Reinforcement Learning Nanodegree, and has been adjusted for being used with the Tennis Environment.\n",
    "\n",
    "The code consist of :\n",
    "\n",
    "- `networkforall.py` : In this python file, a PyTorch `Network()` class are implemented which inherits nn.Module base class. This is a regular fully connected Deep Neural Network using the [PyTorch Framework](https://pytorch.org/docs/0.4.0/). The actor network will be trained to generate the actions to perform depending on the environment observed states while the critic network will be trained to evaluate the advantage of such actions. These Neural Networks are used by the DDPG agent and is composed of :\n",
    "\n",
    "  - Actor network\n",
    "      - by setting `actor=True` in the constructor\n",
    "      - input layer of size equal to the `input_dim` (24)\n",
    "      - 2 hidden fully connected layers of `hidden_in_dim` and `hidden_out_dim` cells each\n",
    "      - output layer which returns the actions to be taken by the agent, depends on the `action_size` parameter passed in the constructor, which is 2 in our problem\n",
    "      \n",
    "  - Critic network\n",
    "      - by setting `actor=False` in the constructor\n",
    "      - input layer of `input_dim` (48)\n",
    "      - 1st hidden fully connected layers of `hidden_in_dim` cells with **4** extra units sourcing the action values\n",
    "      - 2nd hidden fully connected layers of `hidden_out_dim` cells\n",
    "      - output layer which returns the Q-value of size 1\n",
    "  \n",
    "\n",
    "- `maddpg.py` : In this python file, a MADDPG agent is defined.\n",
    "\n",
    "    - The `MADDPG` class is implemented, as described in the DDPG algorithm. It provides several methods :\n",
    "  \n",
    "    - `__init__()` (constructor): \n",
    "      - Initialize 2 instance of the `DDPGAgent` (see below), representing the two tennis players in the problem\n",
    "      - sourcing in the discount factor for $\\gamma$, and $\\tau$\n",
    "      \n",
    "    - `act()`:\n",
    "      - It returns actions for the given state as per current policy (actor) network \n",
    "      - Add noise to each step the actor is taking\n",
    "      \n",
    "    - `target_act()`:\n",
    "      - It returns actions for the given state as per current target policy (actor) network \n",
    "      - It is off-policy which will ignore the noise added to the true actions. \n",
    "      \n",
    "    - `update()`:\n",
    "      - which update both agents' critic and actor Neural Network value parameters by standard training procedure using given batch of experiences from the Replay Buffer\n",
    "      \n",
    "    - `update_targets()`:\n",
    "      - update the two *target* networks' weights with continuous blending from the current weight values from the *local* network with parameter `self.tau`\n",
    "\n",
    "\n",
    "- `ddpg_agent.py` : In this python file, a `DDPGAgent` is defined.\n",
    "\n",
    "  - The `DDPGAgent` class is implemented, as described in the DDPG algorithm. It provides several methods :\n",
    "    - `__init__ ()` constructor : \n",
    "      - Initialize the OUNoise instance\n",
    "      - Initialize 2 instance of the Actor  Neural Network : the *target* network and the *local* network\n",
    "      - Initialize 2 instance of the Critic Neural Network : the *target* network and the *local* network\n",
    "      - Initialize the target networks the be same as the local networks\n",
    "      - Initialize the optimizer for local networks\n",
    "      \n",
    "    - `act()`:\n",
    "      - It returns actions for the given state as per current policy (actor) network \n",
    "      - Add noise to each step the actor is taking\n",
    "      \n",
    "    - `target_act()`:\n",
    "      - It returns actions for the given state as per current target policy (actor) network \n",
    "      - It is off-policy which will ignore the noise added to the true actions. \n",
    "\n",
    "\n",
    "- `buffer.py` : \n",
    "\n",
    "  - The ReplayBuffer class implements a fixed-size buffer to store experience tuples  (state, action, reward, next_state, done) \n",
    "    - `push()` allows to add an experience step to the memory\n",
    "    \n",
    "    - `sample()` allows to randomly sample a minibatch of experience steps for the learning  \n",
    "\n",
    "\n",
    "- `OUNoise.py` : \n",
    "\n",
    "  - The OUNoise class implements Ornstein-Uhlenbeck process to serve an exploration mechanism for the action \n",
    "    - `reset()` allows to reset the internal state (= noise) to mean (`self.mu`)\n",
    "    \n",
    "    - `noise()` allows to randomly return a noise sample to be added to the action\n",
    "    \n",
    "    \n",
    "- `main_tennis.py` : This python file is the main entry to the problem, which allows to train the agent. Moreover, it allows to :\n",
    "  - Import the Necessary Packages \n",
    "  - Examine the State and Action Spaces\n",
    "  - Take Random Actions in the Environment\n",
    "  - Train an agent using `MADDPG()` class, the main function of training is called `update()`\n",
    "  - Use Tensorboard and Progressbar to monitor the training procedure\n",
    "  - Plot the scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADDPG Parameters and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are six hyper-parameters related to the DDPG Agent itself. The hyperparameters of the agent are listed as below:\n",
    "\n",
    "```python\n",
    "\n",
    "Actor_LAYER_1 = 512    # size of 1st fully connected layer in the actor network\n",
    "Actor_LAYER_2 = 256    # size of 2nd fully connected layer in the actor network\n",
    "Critic_LAYER_1 = 512   # size of 1st fully connected layer in the critic network\n",
    "Critic_LAYER_2 = 256   # size of 2nd fully connected layer in the critic network\n",
    "\n",
    "lr_actor  = 1.0e-2      # learning rate of the actor \n",
    "lr_critic = 1.0e-3      # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0001   # exponential decay rate for moment estimates in Adam\n",
    "\n",
    "GAMMA = 0.99            # discount factor for Q value calculation\n",
    "TAU   = 1e-2            # for soft update of target parameters\n",
    "```\n",
    "Note that in principle one can use different network structure for actor and critic network. Here, to reduce some complexity of the system I have used the same structure for both networks and the sizes listed above turned out to be enough to generate good performance. \n",
    "\n",
    "To reduce the variance of future steps in the TD(1) evaluation, I have reduced the discount rate from 0.99 to 0.98 which receives a good effect. \n",
    "\n",
    "The two learning rate was the major hyper-parameters for me to tune. In order to get a well guided direction for the tuning, I leverage the [tensorboard](https://pytorch.org/docs/stable/tensorboard.html) capability within PyTorch. Details can be found in the next subsection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer Hyperparameters\n",
    "The Replay Buffer has two hyperparameters that determine the size of the buffer and sample size of the minibatch:\n",
    "```python\n",
    "buffersize = int(5e4)   # replay buffer size\n",
    "batchsize  = 512        # minibatch size\n",
    "```\n",
    "\n",
    "As indicated in the previous section, the size of the buffer was tuned to have enough samples which is a critical point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUNoise Hyperparameters\n",
    "The Ornstein-Uhlenbeck process itself has three hyperparameters that determine the noise characteristics and magnitude:\n",
    "- mu: the long-running mean\n",
    "- theta: the speed of mean reversion\n",
    "- sigma: the volatility parameter\n",
    "\n",
    "Of these, I only tuned sigma and theta. After running a few experiments, I reduced sigma from 0.2 to 0.1. The reduced noise volatility seemed to help the model converge faster.\n",
    "\n",
    "Notice also there's an epsilon parameter used to decay the noise level over time. I got this idea from [Remy Hamilton-Smith](https://github.com/Remtasya/Distributional-Multi-Agent-Actor-Critic-Reinforcement-Learning-MADDPG-Tennis-Environment/blob/master/Report.md), although I should say it is a natural adaption from the magnitude of $\\epsilon$-greedy policy. This decay mechanism ensures that more noise is introduced earlier in the training process (i.e., higher exploration), and the noise decreases over time as the agent gains more experience (i.e., higher exploitation). The decay rate of OU Noise is tuned during experimentation. Also, the decaying of the noise scale is controlled in such a way that we only decrease the noise while there are signs of score improvement. Lastly, we also control the minimum scale of noise to ensure, there is always a little exploration left no matter what. The minimum bound of the noise scale is set at 0.05 as shown below. \n",
    "\n",
    "You can find the epsilon process implemented [here](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/main_tennis.py#L198) in the `main_tennis.py` of the source code. \n",
    "\n",
    "The final noise parameters were set as follows:\n",
    "\n",
    "```python\n",
    "NOISE_SIGMA = 0.1              # Ornstein-Uhlenbeck noise vol parameter\n",
    "NOISE_THETA = 0.1              # Ornstein-Uhlenbeck noise speed parameter\n",
    "EPSILON_DECAY = 0.998          # decay rate for noise process\n",
    "noise_low_threshold = 0.05     # lower bound for the noise scale decay multiplier \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise scale profile can be seen from the following image:\n",
    "![Noise Scale](images/noise_scale.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning and Monitoring\n",
    "\n",
    "Admittedly, this is a harder project to crack down. I have used significantly more effort than the first two projects did to reach the performance that was satisfactory. Some of them are due to my personal work and life constraints. More are attributed to the notorious complex nature of the problem. \n",
    "\n",
    "As is well known in the AI community, all the AI programs would experience two stage of debugging: code debug and hyper-parameters debug. In terms of code debugging, it is relatively easy and straight forward, although time consuming, there are well developed tools and general practices to follow. It took only a day to adapt codes from the Physical Deception lab to run without problems in the current settings. \n",
    "\n",
    "However, hyper-parameter tunning/debugging is a much more complicated process. As counted from above, we have 15 hyper-parameters to tune in this project and not each and everyone had the same effect on the final outcome. And initially one has no clue of what is a more important parameter to tune. To gain insight about the training process I used the following code to launch a Tensorboard environment:\n",
    "\n",
    "```python\n",
    "%tensorboard --logdir logs \n",
    "```\n",
    "\n",
    "One can see in tensorboard that different training iterations are put into different folder and shown in different colors. In each iteration, I ran episodes up to **10k**, and the episode number is indicated on the horizontal axis.\n",
    "\n",
    "To facilitate the process, I added several tensorboard logger at different places of the codes. For example, the noise scale logger would reveal the plots shown above. Next, I monitor the detail actions of the agent took to see what kind action spaces have been covered, as can be seen [here](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/main_tennis.py#L75). Furthermore, I have noted down the loss functions of the actor and the critic network to see how the losses are minimized during the training, as shown [here](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/main_tennis.py#L155). \n",
    "\n",
    "Initially, I was using the same learning rate for the actor and the critic. However, after noticing that the critic loss function has some large swings, I lowered the learning rate for the critic and thus achieved much better and stable training. \n",
    "These tensorboard logging functions gave me tremendous help on the direction for tuning hyper-parameters. The detail tuning processes facilitated by those metrics will be discussed below. \n",
    "\n",
    "Let us now have a detail look at the loss functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic Losses\n",
    "\n",
    "The grey line shows the agent0's critic loss function, while the blue one shows that for agent1. Note that the two agents' loss functions are pretty similar and steadily decreasing. This symbolize that the learning rate for critic Network is appropriate, at least not too high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/critic_losses.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Losses\n",
    "\n",
    "The orange line shows the agent0's actor loss function, while the red one shows that for agent1. Note that the two agents' loss functions are again showing similar patterns. Initially, the loss functions are increasing. The most interesting thing I learned from this project is that I need to be patient with the training process. For a long time the MADDPG agent could not reach the target performance and I almost lost confidence in the implementation. However, At around episode 8k, there is a kink in the actor's loss function, at which point the actor loss functions start to decrease and agents start to rapidly pick up the score (as can be seen from the result section). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/actor_losses.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_acc = EventAccumulator(\"./log_final/events.out.tfevents.final\")\n",
    "event_acc.Reload()\n",
    "w_times, step_nums, vals = zip(*event_acc.Scalars('result/final_metric'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(step_nums, vals)\n",
    "plt.axhline(y=0.5, color = 'r')\n",
    "plt.axvline(x=8350, color = 'y')\n",
    "plt.ylabel('Average Score of last 100 Episodes')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final metric as indicated in the [README](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/README.md) of the project, and also implemented [here](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/main_tennis.py#L197) in the code, can be plotted as above. One can see above that the problem is solved at around episode 8350. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5044000148773193\n"
     ]
    }
   ],
   "source": [
    "print(vals[8350])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final pytorch model results for MADDPG are stored in the `model_final` folder. The performance of the model can be accessed from the [`trained_agent`](https://github.com/readerwei/Reinforcement_Learning_Degree/blob/master/p3_collab-compet/trained_agent.ipynb) notebook. The bottom line is that using the trained smart agent, one can easily get a score of \n",
    "**1.9** for one episode. \n",
    "\n",
    "Note that one can watch the real time smart agent playing tennis by setting `train_mode=False` in the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADDPG Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expedite the training process\n",
    "\n",
    "Although I have been trying my best to seek the best model to make my agent reach the target performance as soon as possible, it still took almost 8500 episodes to solve the problem. On the other hand, other [people](https://github.com/Remtasya/Distributional-Multi-Agent-Actor-Critic-Reinforcement-Learning-MADDPG-Tennis-Environment/blob/master/Report.md) claims that they could solve the problem much faster. I ran at least 30 different combinations in searching for a good set of hyperparameters, so perhaps implementing a more systemic approach such as grid search would help. On the other hand, the extreme high dimensionality of the parameter space would prevent such a brute force grid search and thus more insights needs to be shed on the training process. \n",
    "\n",
    "### Add prioritized experience replay  \n",
    "\n",
    "Rather than selecting experience tuples randomly, prioritized replay selects experiences based on a priority value that is correlated with the magnitude of error. This can improve learning by increasing the probability that rare or important experience vectors are sampled.\n",
    "\n",
    "### Add policy ensembles\n",
    "\n",
    "As previously mentioned, a recurring problem in multi-agent reinforcement learning is the environment non-stationarity due to the agents’ changing policies. This is particularly true in competitive settings, where agents can derive a strong policy by overfitting to the behavior of their competitors. Such policies are undesirable as they are brittle. To obtain multi-agent policies that are more robust to changes in the policy of competing agents, there are proposals to train a collection of K different sub-policies. At each episode, one may randomly select one particular sub-policy for each agent to execute. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Multi-Agent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from MADDPG Algorithms, there are several other significantly important advances in the field of MARL as listed in the paper of [*Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms*](https://arxiv.org/pdf/1911.10635.pdf), I should also try to implement algorithms there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "udacity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
