{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=24, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from networkforall import Network\n",
    "\n",
    "actor_0 = Network(24, 512, 256, 2, actor=True)\n",
    "actor_1 = Network(24, 512, 256, 2, actor=True)\n",
    "\n",
    "checkpoint = torch.load('model_dir/2021_01_16_13_53/episode-8500.pt')\n",
    "actor_0.load_state_dict(checkpoint[0]['actor_params'])\n",
    "actor_1.load_state_dict(checkpoint[1]['actor_params'])\n",
    "actor_0.eval()\n",
    "actor_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 24])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[0][\"actor_params\"][\"fc1.weight\"].shape)\n",
    "print(checkpoint[0][\"actor_params\"][\"fc2.weight\"].shape)\n",
    "print(checkpoint[0][\"actor_params\"][\"fc3.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0.0001,\n",
       "  'amsgrad': False,\n",
       "  'params': [0, 1, 2, 3, 4, 5]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint[0][\"actor_optim_params\"][\"param_groups\"]\n",
    "checkpoint[0][\"critic_optim_params\"][\"param_groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.65800002 1.66800002]\n"
     ]
    }
   ],
   "source": [
    "rewards_overall = np.zeros(2)\n",
    "\n",
    "for episode in range(2):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    states = env_info.vector_observations\n",
    "    obs = [agent_obs for agent_obs in states]\n",
    "    \n",
    "    for episode_t in range(1000):\n",
    "\n",
    "        agent_0_action = actor_0(torch.from_numpy(obs[0]).float()).detach().numpy()\n",
    "        agent_1_action = actor_1(torch.from_numpy(obs[1]).float()).detach().numpy()\n",
    "        \n",
    "        actions_array = np.stack([agent_0_action,agent_1_action])\n",
    "        \n",
    "        env_info = env.step(actions_array)[brain_name]  \n",
    "\n",
    "        next_states = env_info.vector_observations\n",
    "        next_obs = [agent_obs for agent_obs in next_states]\n",
    "\n",
    "        rewards = np.array(env_info.rewards)\n",
    "        \n",
    "        dones = np.array(env_info.local_done)\n",
    "\n",
    "        obs = next_obs\n",
    "        \n",
    "        rewards_overall += rewards\n",
    "        \n",
    "        if np.any(dones):\n",
    "            break\n",
    "            \n",
    "print(rewards_overall/(episode+1)) # average rewards over 100 episodes without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_of_episodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3be482364ecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m hyper_dict   = {\"number_of_episodes\": number_of_episodes, \n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[1;34m\"episodes_before_training\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepisodes_before_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[1;34m\"learn_per_episode\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearn_per_episode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[1;34m\"batchsize\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m\"noise_start_scale\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'number_of_episodes' is not defined"
     ]
    }
   ],
   "source": [
    "hyper_dict   = {\"number_of_episodes\": number_of_episodes, \n",
    "                \"episodes_before_training\": episodes_before_training,\n",
    "                \"learn_per_episode\": learn_per_episode, \n",
    "                \"batchsize\": batchsize, \n",
    "                \"noise_start_scale\" : noise,\n",
    "                \"noise_reduction\": noise_reduction,\n",
    "                \"noise_low_threshold\": noise_low_threshold,\n",
    "                \"discount_factor\" : val_dics, \n",
    "                \"tau\" : val_tau\n",
    "               }\n",
    "torch.save(hyper_dict, os.path.join(model_dir, 'hyperparam.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "udacity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
